{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #                 [Lab 03] Analise de sentimentos do Twitter\n",
    "\n",
    "Projeto que tenta analisar como os brasileiros reagiram com a notícia que Neymar nao foi indicado ao título de melhor do mundo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re,string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import operator\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo dados\n",
    "\n",
    "Foram coletados quase 60 mil twittes com emojis e classificados como positivos ou negativos, com base nos emojis utilizados. \n",
    "\n",
    "Os dados estao no arquivo db.csv e eh utilizado o codigo abaixo para ler esse arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('db.csv', sep='\\t') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando uma amostra\n",
    "\n",
    "Para que possamos trabalhar de forma eficiente (tempo de execucao, memoria), coletamos uma amostra desse data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['sentiment'] == 0].sample(n = int(0.1*df.shape[0])) #pega 10% dos tweets negativos\n",
    "df_1 = df[df['sentiment'] == 1].sample(n = int(0.1*df.shape[0])) #pega 10% dos tweets positivos\n",
    "\n",
    "df = df_0.append(df_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sera necessario fazer uma limpeza nos tweets\n",
    "\n",
    "Abaixo estao alguns metodos para limpar os tweets antes de processa-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "def remove_mention(text):\n",
    "    new_text = \"\"\n",
    "    list_of_words = text.split(\" \")\n",
    "    for word in list_of_words:\n",
    "        if word[0] != \"@\":\n",
    "            new_text = new_text + word + \" \"\n",
    "    return new_text.rstrip()\n",
    "\n",
    "def remove_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def remove_pics(text):\n",
    "    new_text = \"\"\n",
    "    list_of_words = text.split(\" \")\n",
    "    for word in list_of_words:\n",
    "        if len(word) < 32:  ##ver a representacao da imagem melhor para evitar de remover outras palavras\n",
    "            new_text = new_text + word + \" \"\n",
    "    return new_text.rstrip()\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def remove_numbers(text):\n",
    "    new_text = \"\"\n",
    "    list_of_words = text.split(\" \")\n",
    "    for word in list_of_words:\n",
    "        if not(is_number(word)) :\n",
    "            new_text = new_text + word + \" \"\n",
    "    return new_text.rstrip()\n",
    "\n",
    "def clean_tweet(text):\n",
    "    return remove_numbers(remove_punctuation(remove_links(remove_pics(remove_mention(text)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indice invertido\n",
    "\n",
    "Cria o Indice invertido, como foi visto no Lab01, para que possa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria um mapa de tokens relacionando o indice do tweet e suas palavras\n",
    "\n",
    "df['tokens'] = df.apply(lambda row: Counter(nltk.word_tokenize(clean_tweet(row['text'].lower()))), axis=1)\n",
    "\n",
    "# cria o indice invertido a partir dos tokens gerados\n",
    "\n",
    "inverted_index = {}\n",
    "\n",
    "for token_list, _id in zip(df.tokens, df.id):\n",
    "    for token in token_list.keys():\n",
    "        if token not in inverted_index.keys():\n",
    "            inverted_index[token] = [_id]\n",
    "        else:\n",
    "            inverted_index[token].append(_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "Funcoes para calcular o TF-IDF de cada termo do Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    N = df.shape[0] # tamanho do corpus\n",
    "    return np.log(N/len(inverted_index[term.lower().strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term):\n",
    "    return len(inverted_index[term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidfs(tokens_list):\n",
    "    resp = {}\n",
    "    for token in tokens_list:\n",
    "        resp[token] = tf(token)*idf(token)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topicos\n",
    "\n",
    "#### Seleciona as palavras mais relevantes daquele tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(tokens_list, n= 25):\n",
    "    tfidfs = get_tfidfs(tokens_list)\n",
    "    \n",
    "    sorted_d = sorted(tfidfs.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    \n",
    "    return [topic[0] for topic in sorted_d[:n]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topics'] = df.apply(lambda row: get_topics(row['tokens']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topics'] = df.apply(lambda row: get_topics(row['tokens']), axis=1)\n",
    "df_processed = df[['id','topics', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_processed.drop('topics', 1).join(df.topics.str.join('|').str.get_dummies(), lsuffix = \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir os dados\n",
    "\n",
    "Nesse ponto precisamos de uma porcentagem dos dados para treinar o modelo e outra porcentagem para testar o modelo. Escolhi 80% pra treino e 20% pra teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_processed[[i for i in list(df_processed.columns) if i not in ['id', 'sentiment']]]\n",
    "\n",
    "X = df_temp.as_matrix()\n",
    "y = df_processed[['sentiment']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador\n",
    "\n",
    "Aqui criamos o modelo a partir do algoritmo Naive Bayes Multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "model_mnb = mnb.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "model_bnb = bnb.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste do modelo\n",
    "\n",
    "Com o modelo ja treinado agore precisamos testa-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos \n",
    "y_pred = model_mnb.predict(X_test)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos inicialmente a acurácia. Que mostra a porcentagem de acertos/numero total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7250430292598967"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos também matriz de confusão para saber mais detalhes dos acertos e erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[930, 254],\n",
       "       [385, 755]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhoramento o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de chegar nesse resultado do modelo, foi necessário muitos testes e mudanças. \n",
    "\n",
    "Minha primeira implementação utilizava o algoritmo Gaussian Naive Bayes para classificação pois foi o primeiro que encontrei que utilizava naive bayes. Também utilizei apenas 5% da base de dados (cerca de 3 mil tweets) e selecionava apenas 3 palavras como tópicos de cada tweet. Foi uma escolha que visava a agilidade de processamento e testes durante a programação. Com essas configurações, a acurácia era pouco mais de 50%. E vendo mais detalhes, utilizando a matriz de confusão, percebi que ele classificava quase todos os tweets como positivo. Por isso acertava todos os positivos e errava quase todos os negativos. \n",
    "\n",
    "Imaginei inicialmente que poderia ser o número de tópicos, então resolvi aumentar de 3 para 5. De fato, houve uma melhora na acurácia porém continuava abaixo 55%. Aumentei o número de tópicos para 10, depois 20 e então consegui chegar aos 55%. O problema que por mais que eu aumentasse o número de tópicos, nesse ponto o valor não melhorava. Resolvi então aumentar o número da amostra. Agora coletava 2%, porém nesse ponto comecei a ter problemas de estouro de memória. então vi que não adiantava forçar mais, agora a mudança tinha que ser no modelo ou na forma de tratar os tweets. \n",
    "\n",
    "Então fiz diversas limpezas nos tweets, removendo assim mentions, links e imagens. Tudo isso proporcionou uma pequena melhoria, mas nada muito mais do que 66% de acurácia. \n",
    "\n",
    "Estava muito insatisfeito com meu modelo. Pensei então em utilizar outro algoritmo, uma rede neural, por exemplo. E nessa pesquisa descobri que havia outras variações do naive bayes. E então utilizando o algoritmo Multinominal Naive Bayes foi possível atingir os 75%. \n",
    "\n",
    "Provavelmente uma melhor limpeza nos tweets, uma melhor classificação (não utilizando apenas emojis para classificar, adicionar uma nova categoria para os neutros) ou utilizar uma amostra maior, seria possível melhorar essa acurácia. Mas a níveis de estudo acredito que foi encontrado um bom modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso do modelo\n",
    "\n",
    "Agora que temos um bom modelo, gostaria de testa-lo em um conjunto de 30 tweets, classificados à mão por mim,  sobre a entrevista de bolsonaro no roda viva. Vamos ver como nosso modelo sai em outros contextos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos primeiro pegar esses dados e deixa-los na mesma dimensão que o classificador consiga ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('bols6.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_resp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-fe15309635f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet_topics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_resp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#fill the row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_resp' is not defined"
     ]
    }
   ],
   "source": [
    "tweets_test = []\n",
    "\n",
    "num_columns_to_train = X_train.shape[1]\n",
    "\n",
    "for tweet_topics in new_df:\n",
    "    row = np.zeros((df_resp.shape[1],), dtype=int)\n",
    "    \n",
    "    #fill the row\n",
    "    for topic in tweet_topics:\n",
    "        if topic in (df_processed.columns.values):\n",
    "            idx = df_processed.columns.get_loc(topic)\n",
    "            row[idx] = 1\n",
    "    \n",
    "    tweets_test.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora jogar esse novo data frame no classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(tweets_test)\n",
    "y_real = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ver os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_real, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver, pela acurácia que o modelo \n",
    "Também podemos observar, pela matriz de confusão, que o modelo erra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
