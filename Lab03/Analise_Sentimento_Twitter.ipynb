{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #                 [Lab 03] Analise de sentimentos do Twitter\n",
    "\n",
    "Projeto que tenta criar um modelo de analise de sentimento com base em tweets com emojis, e dai tentar utilizar esse classificador em outros contextos. O caso escolhido seria saber se ele se enquadraria para analisar o sentimento dos eleitores em rela√ß√£o ao Bolsonaro, ap√≥s sua entrevista ao roda viva.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re,string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import operator\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo dados\n",
    "\n",
    "Foram coletados quase 60 mil twittes com emojis e classificados como positivos ou negativos, com base nos emojis utilizados. \n",
    "\n",
    "Os dados estao no arquivo db.csv e eh utilizado o codigo abaixo para ler esse arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('db.csv', sep='\\t') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando uma amostra\n",
    "\n",
    "Para que possamos trabalhar de forma eficiente (tempo de execucao, memoria), coletamos uma amostra desse data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['sentiment'] == 0].sample(n = int(0.1*df.shape[0])) #pega 10% dos tweets negativos\n",
    "df_1 = df[df['sentiment'] == 1].sample(n = int(0.1*df.shape[0])) #pega 10% dos tweets positivos\n",
    "\n",
    "df = df_0.append(df_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sera necessario fazer uma limpeza nos tweets\n",
    "\n",
    "Abaixo estao alguns metodos para limpar os tweets antes de processa-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "def remove_mention(text):\n",
    "    new_text = \"\"\n",
    "    list_of_words = text.split(\" \")\n",
    "    for word in list_of_words:\n",
    "        if word[0] != \"@\":\n",
    "            new_text = new_text + word + \" \"\n",
    "    return new_text.rstrip()\n",
    "\n",
    "def remove_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def remove_pics(text):\n",
    "    new_text = \"\"\n",
    "    list_of_words = text.split(\" \")\n",
    "    for word in list_of_words:\n",
    "        if len(word) < 32:  ##ver a representacao da imagem melhor para evitar de remover outras palavras\n",
    "            new_text = new_text + word + \" \"\n",
    "    return new_text.rstrip()\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def remove_numbers(text):\n",
    "    new_text = \"\"\n",
    "    list_of_words = text.split(\" \")\n",
    "    for word in list_of_words:\n",
    "        if not(is_number(word)) :\n",
    "            new_text = new_text + word + \" \"\n",
    "    return new_text.rstrip()\n",
    "\n",
    "def clean_tweet(text):\n",
    "    return remove_numbers(remove_punctuation(remove_links(remove_pics(remove_mention(text)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indice invertido\n",
    "\n",
    "Cria o Indice invertido, como foi visto no Lab01, para que possa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria um mapa de tokens relacionando o indice do tweet e suas palavras\n",
    "\n",
    "df['tokens'] = df.apply(lambda row: Counter(nltk.word_tokenize(clean_tweet(row['text'].lower()))), axis=1)\n",
    "\n",
    "# cria o indice invertido a partir dos tokens gerados\n",
    "\n",
    "inverted_index = {}\n",
    "\n",
    "for token_list, _id in zip(df.tokens, df.id):\n",
    "    for token in token_list.keys():\n",
    "        if token not in inverted_index.keys():\n",
    "            inverted_index[token] = [_id]\n",
    "        else:\n",
    "            inverted_index[token].append(_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "Funcoes para calcular o TF-IDF de cada termo do Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    N = df.shape[0] # tamanho do corpus\n",
    "    return np.log(N/len(inverted_index[term.lower().strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term):\n",
    "    return len(inverted_index[term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidfs(tokens_list):\n",
    "    resp = {}\n",
    "    for token in tokens_list:\n",
    "        resp[token] = tf(token)*idf(token)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topicos\n",
    "\n",
    "#### Seleciona as palavras mais relevantes daquele tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(tokens_list, n= 25):\n",
    "    tfidfs = get_tfidfs(tokens_list)\n",
    "    \n",
    "    sorted_d = sorted(tfidfs.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    \n",
    "    return [topic[0] for topic in sorted_d[:n]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topics'] = df.apply(lambda row: get_topics(row['tokens']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topics'] = df.apply(lambda row: get_topics(row['tokens']), axis=1)\n",
    "df_processed = df[['id','topics', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_processed.drop('topics', 1).join(df.topics.str.join('|').str.get_dummies(), lsuffix = \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir os dados\n",
    "\n",
    "Nesse ponto precisamos de uma porcentagem dos dados para treinar o modelo e outra porcentagem para testar o modelo. Escolhi 80% pra treino e 20% pra teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_processed[[i for i in list(df_processed.columns) if i not in ['id_', 'sentiment_', \"sentiment\"]]]\n",
    "\n",
    "X = df_temp.as_matrix()\n",
    "y = df_processed[['sentiment']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador\n",
    "\n",
    "Aqui criamos o modelo a partir do algoritmo Naive Bayes Multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "model_mnb = mnb.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uso para teste, para saber qual modelo sai melhor\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "model_bnb = bnb.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste do modelo\n",
    "\n",
    "Com o modelo ja treinado agore precisamos testa-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos \n",
    "y_pred = model_mnb.predict(X_test)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos inicialmente a acur√°cia. Que mostra a porcentagem de acertos/numero total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7375215146299484"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos tamb√©m matriz de confus√£o para saber mais detalhes dos acertos e erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[969, 215],\n",
       "       [395, 745]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhoramento o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de chegar nesse resultado do modelo, foi necess√°rio muitos testes e mudan√ßas. \n",
    "\n",
    "Minha primeira implementa√ß√£o utilizava o algoritmo Gaussian Naive Bayes para classifica√ß√£o pois foi o primeiro que encontrei que utilizava naive bayes. Tamb√©m utilizei apenas 5% da base de dados (cerca de 3 mil tweets) e selecionava apenas 3 palavras como t√≥picos de cada tweet. Foi uma escolha que visava a agilidade de processamento e testes durante a programa√ß√£o. Com essas configura√ß√µes, a acur√°cia era pouco mais de 50%. E vendo mais detalhes, utilizando a matriz de confus√£o, percebi que ele classificava quase todos os tweets como positivo. Por isso acertava todos os positivos e errava quase todos os negativos. \n",
    "\n",
    "Imaginei inicialmente que poderia ser o n√∫mero de t√≥picos, ent√£o resolvi aumentar de 3 para 5. De fato, houve uma melhora na acur√°cia por√©m continuava abaixo 55%. Aumentei o n√∫mero de t√≥picos para 10, depois 20 e ent√£o consegui chegar aos 55%. O problema que por mais que eu aumentasse o n√∫mero de t√≥picos, nesse ponto o valor n√£o melhorava. Resolvi ent√£o aumentar o n√∫mero da amostra. Agora coletava 2%, por√©m nesse ponto comecei a ter problemas de estouro de mem√≥ria. ent√£o vi que n√£o adiantava for√ßar mais, agora a mudan√ßa tinha que ser no modelo ou na forma de tratar os tweets. \n",
    "\n",
    "Ent√£o fiz diversas limpezas nos tweets, removendo assim mentions, links e imagens. Tudo isso proporcionou uma pequena melhoria, mas nada muito mais do que 66% de acur√°cia. \n",
    "\n",
    "Estava muito insatisfeito com meu modelo. Pensei ent√£o em utilizar outro algoritmo, uma rede neural, por exemplo. E nessa pesquisa descobri que havia outras varia√ß√µes do naive bayes. E ent√£o utilizando o algoritmo Multinominal Naive Bayes tivemos media de 75% dos acertos e foi poss√≠vel atingir a marca de 80% de acerto. \n",
    "\n",
    "Provavelmente uma melhor limpeza nos tweets, uma melhor classifica√ß√£o (n√£o utilizando apenas emojis para classificar, adicionar uma nova categoria para os neutros) ou utilizar uma amostra maior, seria poss√≠vel melhorar essa acur√°cia. Mas a n√≠veis de estudo acredito que foi encontrado um bom modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso do modelo\n",
    "\n",
    "Agora que temos um bom modelo, gostaria de testa-lo em um conjunto de 30 tweets, classificados √† m√£o por mim,  sobre a entrevista de bolsonaro no roda viva. Vamos ver como nosso modelo sai em outros contextos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos primeiro pegar esses dados e deixa-los na mesma dimens√£o que o classificador consiga ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\"√â dif√≠cil escolher a maior barbaridade q Bolsonaro disse no Roda Viva.Mas dizer que os africanos eram os respons√°veis pela pr√≥pria escravid√£o q os martirizou e q os portugueses √± pisaram na √Åfrica ,mostra a covardia expl√≠cita deste racista ao tentar transformar a v√≠tima em algoz.\",\n",
    "\"se depois dessa entrevista do bolsonaro no roda viva vc ainda vai votar nele na moral s√≥ digo uma coisa: da unfollow e me corta pq tem que ser MUITO BURRO, n√£o precisa ter nem 2 neuronios\",\n",
    "\"Dps do Bolsonaro no roda viva ficou claro que quem apoia ele tem algum problema mental\",\n",
    "\"√â muita covardia comparar essa entrevista do Ciro Gomes com a palha√ßada que se deu no Roda Viva com Bolsonaro. N√£o entendo como algu√©m pode cogitar aquela mula, comparado ao Ciro ou a qualquer outro candidato.\",\n",
    "\"Vi a entrevista do Bolsonaro pro roda viva e fui ler os coment√°rios, fiquei horrorizada com o tanto de gente que o apoia, n√£o sei mais o que vai virar\",\n",
    "\"Eu sinto tanto nojo dos v√≠deos do Bolsonaro no Roda Viva que n√£o consigo nem compartilhar pra mostrar o quanto ele √© uma merda N√£o √© poss√≠vel esse cara ter tanto f√£ burro meu pai do c√©u\",\n",
    "\"Voc√™ viu o Bolsonaro pagando mico no RodaViva? Elege ele pra ver a vergonha internacional que n√≥s iremos passar!\",\n",
    "\"Bolsonaro no Roda Viva se mostrou totalmente incapaz de governar algo, ele n√£o t√° apto nem pra gerir uma bodega quem dera um pa√≠s. Fora o conhecimento zero em hist√≥ria, o saudosismo a ditadura passando pano pra tortura e os assassinatos, e outras baboseiras ditas, ele √© um asno.\",\n",
    "\"o indiv√≠duo que assistiu o roda viva com bolsonaro e ainda assim ESCOLHE votar nele tem mais √© que receber o t√≠tulo de ot√°rio mesmo\",\n",
    "\"eu to chocada com as respostas que o bolsonaro deu no roda viva mano MANO M A N O como, COMO, C O M O algu√©m consegue ver um bom futuro pro nosso pa√≠s com esse cara na presid√™ncia? PUTA MERDA\",\n",
    "\"Depois das aberra√ß√µes de ontem de Bolsonaro, √© ainda mais claro que a educa√ß√£o p√∫blica precisa incluir a defesa dos direitos humanos e da democracia. Sem acertar contas com o passado, n√£o h√° presente nem futuro. Como se diz em psican√°lise, √© um passado que n√£o passa.\",\n",
    "\"confesso q n√£o consegui assistir a entrevista inteira do Bolsonaro no Roda Viva.me faz muito mal ouvir aquele ser odioso falar, faz muito mal pro Brasil darem voz pra aquilo, √© p√©ssimo pro povo brasileiro, j√° t√£o sofrido, sentir o √≥dio se propagando enquanto o amor segue preso.\",\n",
    "\"O #RodaViva de ontem mostrou novamente que n√£o precisamos perder nosso tempo difamando o bolsonaro. Ele j√° faz isso muito bem sozinho.¬Ø\\_(„ÉÑ)_/¬Ø\",\n",
    "\"Eu creio que o Bolsonaro no #RodaViva diminuiu ainda mais as chances dele vencer alguma coisa Voc√™ pode ser \"\"anti-esquerda\"\", mas voc√™ n√£o √© idiota a ponto de votar em algu√©m claramente despreparado Fale o que quiser, mas n√£o diga que ele √© preparado para ser presidente.\",\n",
    "\"Assistindo o #RodaViva com o Bolsonaro e n√£o consigo sentir nada al√©m de medo. Medo de ver pessoas apoiando algu√©m desequilibrado apenas por estarem desesperados por mudan√ßas. Medo ao imaginar algu√©m como ele governando um pa√≠s.\",\n",
    "\"Os jornalistas do Roda Viva deveriam descer do pedestal pq o Bolsonaro se saiu muito melhor que eles. #OsPingosNosIs\",\n",
    "\"Pensando na maneira que foi conduzida a √∫ltima entrevista no Roda Viva ser√° mesmo que nosso candidato Bolsonaro dever√° participar nas demais?! O que vimos foi um bando de abutres tentando desqualifica-lo e ele tem mto mais a oferecer do que ficar dando aula de hist√≥ria!!\",\n",
    "\"O Bolsonaro foi perfeito em todas as quest√µes, os esquerdoburros do @rodaviva n√£o conseguiram sequer pegar a placa da jamanta que os atropelou! üòÇüòÇüòÇ\",\n",
    "\"ESPETACULAR!!! RECORDE QUE NEM ESSE DUVIDO Q OUTRO POL√çTICO BATER√Å NOS PR√ìXIMOS 50 ANOS! Em menos de 48 horas, o v√≠deo do @jairbolsonaro no Roda Viva acabou de ultrapassar a absurda marca de 4 MILH√ïES DE VISUALIZA√á√ïES (+1 milh√£o em 20 horas) e AINDA CONTINUA EM ALTA no YouTube!\",\n",
    "\"Roda viva mostrou a face mais est√∫pida de um jornalismo descomprometido com a verdade, totalmente amador e ideol√≥gico. Simplesmente rid√≠culo. Um tribunal com ju√≠zes de araque. Bolsonaro s√≥ ganhou. De novo.\",\n",
    "\"Paulo Figueiredo resumiu ‚Äúvoc√™s viram o Bolsonaro no Roda Viva? Eu vi um brasileiro comum falando verdades a uma classe jornal√≠stica est√∫pida, ideol√≥gica, vagabunda, despreparada e soberba. Poucas vezes vi algo t√£o ilustrativo do momento em que vivemos ‚Äú #BolsonaroNoRodaViva\",\n",
    "\"Jair Bolsonaro sai fortalecido do programa Roda Viva. O m√©todo de inserir apenas militantes para derrub√°-lo foi um tiro no p√©. Militantes s√£o mon√≥tonos, possuem ret√≥rica limitada e n√£o t√™m compromisso com a realidade dos fatos.\",\n",
    "\"Jair Bolsonaro 7 x 1 Roda Viva  A grande m√≠dia precisa refletir, n√£o da mais para vender MILITANTE como JORNALISTA, este truque n√£o engana mais ningu√©m ...\",\n",
    "\"Falam que a gente √© burro por apoiar Bolsonaro, mas apoia o socialismo e ainda diz que Lula √© inocente. N√£o √© que a gente seja burro, s√£o voc√™s que n√£o aceitam a REALIDADE.  √â @jairbolsonaro 2018 sim, se n√£o gostou vai pra cuba.\",\n",
    "\"Resumo do #RodaViva com BOLSONARO -Ditadura -Ditadura -Tortura -Quilombolas -Jesus era refugiado -Wikipedia -Ditadura - Ex√©rcito Sa√∫de? N√ÉO Saneamento b√°sico? N√ÉO. Educa√ß√£o? N√ÉO.Seguran√ßa? N√ÉO.N√£o vimos uma entrevista. Vimos um folhetim esquerdista baseado na WIKIPEDIA!\",\n",
    "\"O Roda Viva empurrou mais a faixa para o Jair. @jairbolsonaro √© uma esp√©cie de Rocky Balboa, quanto mais apanha, levanta mais forte e motivado.\",\n",
    "\"√â vis√≠vel o √≥dio desses esquerdopatas pelo Bolsonaro. Se Deus quiser, Bolsonaro presidente,\",\n",
    "\"Porra hein, achei muita sacanagem esses jornalixos enchendo o saco do Bolsonaro, sinceramente nem acho que ele precisava disso, deve ser muito estressante pra ele üò§üò§üò°üò°\",\n",
    "\"Fizeram de prop√≥sito s√≥ passado e mimimi para boicotar a entrevista\",\n",
    "\"Meu caro, voc√™ mitou grandemente! üòç\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_processed = [tweet.split() for tweet in tweets ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_test = []\n",
    "\n",
    "num_columns_to_train = X_train.shape[1]\n",
    "\n",
    "for tweet_topics in tweets_processed:\n",
    "    row = np.zeros((df_temp.shape[1],), dtype=int)\n",
    "    \n",
    "    #fill the row\n",
    "    for topic in tweet_topics:\n",
    "        if topic in (df_processed.columns.values):\n",
    "            idx = df_processed.columns.get_loc(topic)\n",
    "            row[idx] = 1\n",
    "    \n",
    "    tweets_test.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora passaremos esses novos tweets para o classificador e coletar o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_mnb.predict(tweets_test)\n",
    "y_real = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ver os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_real, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 12],\n",
       "       [ 2, 13]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_real,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver, pela acur√°cia, que o modelo funciona muito mal fora do seu contexto. Talvez reflita um pouco o tom e palavras ironicos e agressivas que os usu√°rios, de ambos os lados, utilizam ao falar sobre politica e Bolsonaro. \n",
    "Tamb√©m podemos observar, pela matriz de confus√£o, que o modelo erra mais ao julgar que os tweets s√£o negativos quando na verdade s√£o positivos. \n",
    "\n",
    "Algo curioso, que se nota ao rodar esse notebook diversas vezes, √© o fato de que, quando h√° uma melhora na acur√°cia dos testes usando o mesmo contexto do treino, diminui a acur√°cia dos testes com os tweets sobre Bolsonaro. Isso pode nos mostrar sobre o quanto que √© positivo e negativo em um contexto pode ser o oposto em outro.\n",
    "\n",
    "Podemos ent√£o concluir, que para termos melhores resultados no nosso classificador devemos treina-lo de acordo com  precisamos treinar o modelo em um contexto mais espec√≠fico para termos melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
